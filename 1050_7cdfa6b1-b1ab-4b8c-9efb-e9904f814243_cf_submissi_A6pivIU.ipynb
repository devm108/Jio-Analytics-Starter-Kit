{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T14:40:32.045743Z","iopub.execute_input":"2021-07-04T14:40:32.046205Z","iopub.status.idle":"2021-07-04T14:40:32.049588Z","shell.execute_reply.started":"2021-07-04T14:40:32.046174Z","shell.execute_reply":"2021-07-04T14:40:32.048831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class visitlog_transformer:\n    \n    def _init_(self):\n        pass\n    \n    \"\"\"funtion to impute the values on the activity column based on the obeservation click occurs on the same product while\n    #product changes with the pageload\n    \n    # basic idea isto create session id for the users to impute the activity column\n    \n    1---remove the null visittime rows and save it on another df which we will concat later\n    also remove the rows where both the product and activity columns are empty\n    \n    2---grouping by userid and finiding the diff between consecutive entries and if the difference is \n        #longer than 2 hours then marking it as different session\n    \n    3---create the features based on the logic that click occurs on the same product within same session   \n    \"\"\"\n    \n    def impute_activity(self,df):\n        \n        #step1\n        \n        mini_df=df.loc[df.VisitDateTime.isna()]\n        df=df.loc[df.VisitDateTime.notnull()]\n        mini_df=pd.concat([mini_df,df.loc[(df.ProductID.isna())&(df.Activity.isna())]],ignore_index=True)\n        df=df.loc[df.filter(['ProductID','Activity']).dropna(thresh=1).index]\n        \n        #step2\n        df=df.sort_values(['UserID','VisitDateTime']).reset_index(drop=True)\n        df['time_difference']=df.groupby('UserID')['VisitDateTime'].diff(1).dt.total_seconds()/60\n        new_session=((df.time_difference.isna()) | (df.time_difference > 120))\n        df['session_id']=df.loc[new_session,['UserID','VisitDateTime']].groupby('UserID').rank(method='first').astype(int)\n        df['session_id']=df.groupby('UserID')['session_id'].ffill()\n        \n        #step3\n        \n        df['imputed_activity']=0\n        df.loc[df.Activity.isna(),'imputed_activity']=1\n        tobe_imputed=(df.ProductID==df.groupby(['UserID','session_id'])['ProductID'].shift(1))&(df.Activity.isna())\n        df.loc[tobe_imputed,'Activity']='CLICK'\n        tobe_imputed=(df.ProductID!=df.groupby(['UserID','session_id'])['ProductID'].shift(1))&(df.Activity.isna())\n\n        df.loc[tobe_imputed,'Activity']='PAGELOAD'        \n        df=self.impute_product(df)        \n        df=pd.concat([df,mini_df],ignore_index=True).reset_index(drop=True)\n        \n        return (df)\n    \n    \"\"\"impute product based on the observed observation on activity fuction gets called from impute activity\"\"\"\n    def impute_product(self,df):\n        \n        df['imputed_product']=0\n        df.loc[df.ProductID.isna(),'imputed_product']=1\n        df['product_shifted']=df.groupby(['UserID','session_id'])['ProductID'].shift(1)\n        df.loc[(df.ProductID.isna())&(df.Activity=='CLICK'),'ProductID']=df.loc[(df.ProductID.isna())&(df.Activity=='CLICK'),'product_shifted']\n        \n        return (df)\n    \n    \"\"\"   For converting Visitdatetime column to datetime column from string\n    step--1#filter only the unix timestamps and set it as string after converting it to digit\n    step---2 #convert the whole column to datetime column\"\"\"\n    def datetime_clean(self,df):        \n        #step1\n        unix_times=df.VisitDateTime.astype(str).str.isdigit()\n        df.loc[unix_times,'VisitDateTime']=pd.to_datetime(df.loc[unix_times,'VisitDateTime'].astype(str).str[:13],unit='ms').astype(str)\n        #step2        \n        df['VisitDateTime']=pd.to_datetime(df['VisitDateTime'])        \n        df=df.sort_values(['UserID','VisitDateTime']).reset_index(drop=True)\n        \n        return (df)\n        \n    def string_clean(self,df):\n        #cleaning the os and setting title operation inorder to capitalize the first letter    \n        df['OS']=df['OS'].str.lower()\n        \n        df['OS']=df['OS'].str.title()\n        \n        #cleaning the productid column by capitalizing\n        df['ProductID']=df['ProductID'].str.capitalize()\n        \n        #cleaning the Activity column by setting everything in upper case\n        df['Activity']=df['Activity'].str.upper()\n        \n        return (df)\n    \n    def cleandata(self,df):\n        \n        #dropping duplicates incase if there is any        \n        df=df.drop_duplicates()\n        #filtering only the users with UserID\n        df=df.loc[df.UserID.notnull()].reset_index(drop=True)\n        \n        df=self.string_clean(df)\n        \n        df=self.datetime_clean(df)\n        \n        df=self.impute_activity(df)\n        \n        return(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:15:49.285309Z","iopub.execute_input":"2021-07-04T17:15:49.285638Z","iopub.status.idle":"2021-07-04T17:15:49.301885Z","shell.execute_reply.started":"2021-07-04T17:15:49.285610Z","shell.execute_reply":"2021-07-04T17:15:49.300975Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"class user_transformer:    \n    today_date=pd.to_datetime(\"2018-05-28 00:00:30.000000+00:00\")\n    \n    def _init_(self):\n        pass\n        #df['today_date']\n        \n    def vintage_days(self,df):\n        df['User_Vintage']=(pd.to_datetime(\"2018-05-28 00:00:30.000000+00:00\")-df['Signup Date']).dt.days\n        \n        return(df)\n    \n    def cleandata(self,df):\n        \n        df=df.drop_duplicates('UserID')\n        \n        df=df.loc[df.UserID.notnull()].reset_index(drop=True)\n        \n        df['Signup Date']=pd.to_datetime(df['Signup Date'])\n        \n        df['User Segment']=df['User Segment'].fillna('unknown')\n        \n        return df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:15:50.119205Z","iopub.execute_input":"2021-07-04T17:15:50.119539Z","iopub.status.idle":"2021-07-04T17:15:50.125740Z","shell.execute_reply.started":"2021-07-04T17:15:50.119512Z","shell.execute_reply":"2021-07-04T17:15:50.125073Z"},"trusted":true},"execution_count":202,"outputs":[]},{"cell_type":"code","source":"class user_visitlog_transformer:\n\n    def _init_(self):\n        pass\n    \n    def find_most_active_os(self,user_df,log_df):\n        \n        #log_df=logs_df\n        \n        grouped=log_df.groupby('UserID')\n        \n        os_mostactive=grouped['OS'].agg(pd.Series.mode).reset_index().rename(columns={'OS':'Most_Active_OS'})\n        \n        user_df=user_df.merge(os_mostactive,on='UserID',how='left')\n        \n        return(user_df)\n    \n    \n    def recent_viewed_product(self,user_df,log_df):\n        \n        #log_df=logs_df\n        \n        log_df['is_all']=log_df.VisitDateTime.notnull()\n\n        logmini=log_df.loc[log_df.groupby('UserID')['is_all'].transform(sum)==0]\n\n        logmini=logmini.loc[(logmini.ProductID.notnull())]\n\n        logmini=logmini.loc[(logmini.groupby('UserID')['ProductID'].transform('nunique')==1)&(logmini.Activity!='CLICK')]\n\n        logmini=logmini.drop_duplicates(['UserID','ProductID'])\n        \n        log_df=log_df.loc[(log_df.VisitDateTime.notnull())&(log_df.Activity=='PAGELOAD')]\n\n        log_df['is_recent']=log_df.groupby('UserID')['VisitDateTime'].transform(max)==log_df['VisitDateTime']\n\n        #df['is_recent_sum']=df.groupby('UserID')['is_recent'].transform(sum)\n\n        to_join=pd.concat([log_df.loc[(log_df['is_recent']==True),['UserID','ProductID']].drop_duplicates().reset_index(drop=True),logmini[['UserID','ProductID']].drop_duplicates()],ignore_index=True).rename(columns={'ProductID':'Recently_Viewed_Product'})\n\n        user_df=user_df.merge(to_join,on='UserID',how='left')\n\n        user_df['Recently_Viewed_Product']=user_df['Recently_Viewed_Product'].fillna('Product101')\n        \n        return (user_df)\n    \n    \n    def seven_day_feats(self,user_df,log_df):\n        \n        #log_df=logs_df\n        \n        start_date=pd.to_datetime(\"2018-05-21\")\n        \n        end_date=pd.to_datetime(\"2018-05-28\")\n        \n        log_df=log_df.loc[(log_df.VisitDateTime >=start_date)&(log_df.VisitDateTime <end_date)]\n\n        log_df['date']=log_df['VisitDateTime'].dt.date\n\n        features=log_df.groupby('UserID')['date'].nunique().reset_index().rename(columns={'date':'No_of_days_Visited_7_Days'})\n\n        features['No_of_days_Visited_7_Days']=features['No_of_days_Visited_7_Days'].fillna(0)\n\n        features=features.merge(log_df.groupby(['UserID','Activity']).size().unstack().fillna(0).reset_index().rename(columns={'CLICK':'Clicks_last_7_days','PAGELOAD':'Pageloads_last_7_days','UNKNOWN':'Activity_unknown'})[['UserID','Clicks_last_7_days','Pageloads_last_7_days']],on='UserID',how='left')\n\n        features[['Clicks_last_7_days','Pageloads_last_7_days']]=features[['Clicks_last_7_days','Pageloads_last_7_days']].fillna(0)\n        \n        user_df=user_df.merge(features,on='UserID',how='left')\n        \n        user_df[['No_of_days_Visited_7_Days','Clicks_last_7_days','Pageloads_last_7_days']]=user_df[['No_of_days_Visited_7_Days','Clicks_last_7_days','Pageloads_last_7_days']].fillna(0)\n        \n        return(user_df)\n    \n    def fifteen_day_feats(self,user_df,log_df):\n        \n        #log_df=logs_df\n        \n        start_date=pd.to_datetime(\"2018-05-13\")\n        \n        end_date=pd.to_datetime(\"2018-05-28\")\n        \n        log_df=log_df.loc[(log_df.VisitDateTime >=start_date)&(log_df.VisitDateTime <end_date)]\n\n        features=log_df.groupby('UserID')['ProductID'].nunique().reset_index().rename(columns={'ProductID':'No_Of_Products_Viewed_15_Days'})\n\n        features['No_Of_Products_Viewed_15_Days']=features['No_Of_Products_Viewed_15_Days'].fillna(0)\n        \n        user_df=user_df.merge(features,on='UserID',how='left')\n        \n        user_df['No_Of_Products_Viewed_15_Days']=user_df['No_Of_Products_Viewed_15_Days'].fillna(0)\n        \n        return(user_df)\n        \n        #most viewed products\n        \n    def most_viewed_feats(self,user_df,log_df):\n            \n        start_date=pd.to_datetime(\"2018-05-13\")\n        \n        end_date=pd.to_datetime(\"2018-05-28\")\n        \n        log_df['is_all']=True\n        \n        log_df=log_df.loc[(log_df.VisitDateTime >=start_date)&(log_df.VisitDateTime <end_date)]\n        \n        log_df=log_df.loc[(log_df.Activity=='PAGELOAD')&(log_df.ProductID.notnull())]\n\n        log_df['no_of_views']=log_df.groupby(['UserID','ProductID'])['VisitDateTime'].transform(np.size)\n\n        log_df['max_views']=log_df.groupby(['UserID'])['no_of_views'].transform(max)\n\n        log_df=log_df.loc[log_df.no_of_views==log_df.max_views]\n\n        log_df=log_df.loc[(log_df.groupby('UserID')['VisitDateTime'].transform(max)==log_df.VisitDateTime)]\n\n        log_df=log_df.loc[log_df.groupby('UserID')['is_all'].transform('size')==1]\n\n        user_df=user_df.merge(log_df[['UserID','ProductID']].rename(columns={'ProductID':'Most_Viewed_product_15_Days'}),on='UserID',how='left')\n        \n        user_df['Most_Viewed_product_15_Days']=user_df['Most_Viewed_product_15_Days'].fillna('Product101')\n        \n        #user_df=user_df.merge(features,on='UserID',how='left')\n        \n        user_df['Most_Viewed_product_15_Days']=user_df['Most_Viewed_product_15_Days'].fillna(0)\n        return(user_df)\n    \n    \n    def user_visitlog_feats(self,user_df,logs_df):\n        user_transform=user_transformer()\n        user_df=user_transform.cleandata(user_df)\n        visitlog_transform=visitlog_transformer()\n        logs_df=visitlog_transform.cleandata(logs_df)\n        \n        user_df=user_transform.vintage_days(user_df)\n        \n        user_df=self.find_most_active_os(user_df,logs_df)\n        \n        user_df=self.recent_viewed_product(user_df,logs_df)\n        \n        logs_df=logs_df.loc[logs_df.VisitDateTime.notnull()]\n        \n        user_df=self.seven_day_feats(user_df,logs_df)\n        \n        user_df=self.fifteen_day_feats(user_df,logs_df)\n        \n        user_df=self.most_viewed_feats(user_df,logs_df)\n        \n        return(user_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:13:51.436829Z","iopub.execute_input":"2021-07-04T18:13:51.437425Z","iopub.status.idle":"2021-07-04T18:13:51.458007Z","shell.execute_reply.started":"2021-07-04T18:13:51.437390Z","shell.execute_reply":"2021-07-04T18:13:51.457235Z"},"trusted":true},"execution_count":273,"outputs":[]},{"cell_type":"code","source":"user_df=user_df1\n\nlog_df=log_df1\n\nvisitlog_transform=user_visitlog_transformer()\n\nuser_df=visitlog_transform.user_visitlog_feats(user_df,log_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:13:52.358932Z","iopub.execute_input":"2021-07-04T18:13:52.359685Z","iopub.status.idle":"2021-07-04T18:14:38.976874Z","shell.execute_reply.started":"2021-07-04T18:13:52.359631Z","shell.execute_reply":"2021-07-04T18:14:38.975846Z"},"trusted":true},"execution_count":274,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","output_type":"stream"}]},{"cell_type":"code","source":" best=pd.read_csv('../input/analytics-jobs/submission70.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:32:05.681824Z","iopub.execute_input":"2021-07-04T17:32:05.682366Z","iopub.status.idle":"2021-07-04T17:32:05.732395Z","shell.execute_reply.started":"2021-07-04T17:32:05.682320Z","shell.execute_reply":"2021-07-04T17:32:05.731667Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"user_df=user_df.sort_values('UserID').reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:16:31.867212Z","iopub.execute_input":"2021-07-04T18:16:31.867563Z","iopub.status.idle":"2021-07-04T18:16:31.916251Z","shell.execute_reply.started":"2021-07-04T18:16:31.867530Z","shell.execute_reply":"2021-07-04T18:16:31.915265Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"user_df['Most_Active_OS']=user_df['Most_Active_OS'].str.lower()\n\nbest['Most_Active_OS']=best['Most_Active_OS'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T16:33:55.521841Z","iopub.execute_input":"2021-07-04T16:33:55.522220Z","iopub.status.idle":"2021-07-04T16:33:55.569039Z","shell.execute_reply.started":"2021-07-04T16:33:55.522178Z","shell.execute_reply":"2021-07-04T16:33:55.568114Z"},"trusted":true},"execution_count":151,"outputs":[]},{"cell_type":"code","source":"user_df=user_df.sort_values('UserID').reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:14:38.978522Z","iopub.execute_input":"2021-07-04T18:14:38.978789Z","iopub.status.idle":"2021-07-04T18:14:39.046684Z","shell.execute_reply.started":"2021-07-04T18:14:38.978761Z","shell.execute_reply":"2021-07-04T18:14:39.045890Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"best['Most_Active_OS'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T18:18:31.980304Z","iopub.execute_input":"2021-07-04T18:18:31.980773Z","iopub.status.idle":"2021-07-04T18:18:31.990610Z","shell.execute_reply.started":"2021-07-04T18:18:31.980743Z","shell.execute_reply":"2021-07-04T18:18:31.989843Z"},"trusted":true},"execution_count":282,"outputs":[{"execution_count":282,"output_type":"execute_result","data":{"text/plain":"Windows                    20034\nAndroid                     9734\nMac Os X                    2422\nLinux                        920\nIos                          484\nUbuntu                       295\n['Android' 'Windows']        103\nChrome Os                     14\nFedora                        12\n['Ios' 'Windows']              7\n['Android' 'Linux']            7\n['Android' 'Mac Os X']         5\n['Linux' 'Windows']            4\n['Ios' 'Mac Os X']             2\n['Android' 'Ubuntu']           2\n['Mac Os X' 'Windows']         2\n['Ubuntu' 'Windows']           1\n['Android' 'Ios']              1\n['Android' 'Chrome Os']        1\nName: Most_Active_OS, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"user_df['Recently_Viewed_Product'].equals(best['Recently_Viewed_Product'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:58:56.397764Z","iopub.execute_input":"2021-07-04T17:58:56.398132Z","iopub.status.idle":"2021-07-04T17:58:56.412683Z","shell.execute_reply.started":"2021-07-04T17:58:56.398098Z","shell.execute_reply":"2021-07-04T17:58:56.411741Z"},"trusted":true},"execution_count":254,"outputs":[{"execution_count":254,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"user_df['Clicks_last_7_days'].equals(best['Clicks_last_7_days'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:58:57.488243Z","iopub.execute_input":"2021-07-04T17:58:57.488725Z","iopub.status.idle":"2021-07-04T17:58:57.495204Z","shell.execute_reply.started":"2021-07-04T17:58:57.488695Z","shell.execute_reply":"2021-07-04T17:58:57.494488Z"},"trusted":true},"execution_count":255,"outputs":[{"execution_count":255,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"user_df['Pageloads_last_7_days'].equals(best['Pageloads_last_7_days'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:59:03.026019Z","iopub.execute_input":"2021-07-04T17:59:03.026586Z","iopub.status.idle":"2021-07-04T17:59:03.033369Z","shell.execute_reply.started":"2021-07-04T17:59:03.026540Z","shell.execute_reply":"2021-07-04T17:59:03.032408Z"},"trusted":true},"execution_count":256,"outputs":[{"execution_count":256,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"user_df['No_Of_Products_Viewed_15_Days'].equals(best['No_Of_Products_Viewed_15_Days'])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T17:59:04.073175Z","iopub.execute_input":"2021-07-04T17:59:04.073660Z","iopub.status.idle":"2021-07-04T17:59:04.079846Z","shell.execute_reply.started":"2021-07-04T17:59:04.073622Z","shell.execute_reply":"2021-07-04T17:59:04.079194Z"},"trusted":true},"execution_count":257,"outputs":[{"execution_count":257,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"user_df=pd.read_csv(\"/kaggle/input/analytics-jobs/data/data/userTable.csv\")\nlog_df=pd.read_csv(\"/kaggle/input/analytics-jobs/data/data/VisitorLogsData.csv\")\nsample=pd.read_csv(\"/kaggle/input/analytics-jobs/sample_submission_M7Vpb9f.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-04T15:33:45.229086Z","iopub.execute_input":"2021-07-04T15:33:45.229407Z","iopub.status.idle":"2021-07-04T15:33:58.582081Z","shell.execute_reply.started":"2021-07-04T15:33:45.229378Z","shell.execute_reply":"2021-07-04T15:33:58.581338Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}